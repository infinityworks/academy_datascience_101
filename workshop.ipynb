{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# What are we doing here?\n",
    "This is the Infinityworks Data Science 101 workshop. We will be training a model to predict...*drum roll*...The weight of various star wars characters based on their other vital statistics.\n",
    "\n",
    "Don't say we didn't try to make this exciting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Wait, what is this sourcery? Am in an IDE here or what?\n",
    "This is a Jupyter Notebook. It's a standard bit of kit in Data Science circles. It's shite for proper code dev but there's few better tools for doing investigative coding and mixing it with notes and charts. If you want to learn a bit more then there's a link [here](https://github.com/datamacgyver/jupyter_pandas_demo/blob/main/learn_pandas.ipynb).\n",
    "\n",
    "For now, just enjoy the ride and have a play. If, for example, you click on this text you can edit it as Markdown.\n",
    "\n",
    "To run a cell press `ctrl+enter` or `shift+enter`. You will need to do this to see what the code outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### First things first, we need some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd     # Standard Python data handling library. Lets you store tables (often called `DataFrames`)\n",
    "import seaborn as sns   # Plotting library, there's many to choose from but this is a stalwart\n",
    "import matplotlib.pyplot as plt  # Matplotlib is the underlying library to seaborn, it's used to do some fancy stuff later.\n",
    "\n",
    "# Sklearn is the standard Python stats tooling. It's...large and unwieldy but goes.\n",
    "from sklearn.linear_model import LinearRegression                    # Models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # Error metrics\n",
    "from sklearn.model_selection import train_test_split                 # Splitting data (I'll explain later)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Now, some data\n",
    "We aren't going to go too deep into this but you should **ALWAYS** look in depth at your data first, understand where it's coming from and how each bit relates to each other bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pandas makes it easy for us to read a csv straight into a dataframe\n",
    "# Note I'm downloading from the internet here!\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/infinityworks/academy_datascience_101/main/characters.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### These data don't look great!\n",
    "Look at the mass column, there's NaNs (Pandas' version of Null), that will make predicting mass difficult! Let's get rid of them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[~pd.isnull(df.mass)]\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bit of code to break down there:\n",
    "* `df[]` does a filter based on whatever is in the brackets\n",
    "* `~` is a negation, it changes `True` to `False` and vice versa\n",
    "* `pd.isnull()` returns `True` if a value is `NaN`\n",
    "* `df.mass` selects the mass column from the dataframe\n",
    "\n",
    "So - in short - we are filtering for when the mass column is not null."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Now, let's model!\n",
    "Sklearn provides many optimised algorithms/models for Data Science / ML tasks. While you can implement these yourself, the Sklearn versions will be much faster and more efficient for most use cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mod = LinearRegression()\n",
    "\n",
    "# all Sklearn-compatible models use the fit method for training the model\n",
    "mod.fit(df.mass.to_numpy().reshape(-1,1), df.height)\n",
    "\n",
    "# ... and the predict model for making predictions using a trained model\n",
    "df[\"preds\"] = mod.predict(df.height.to_numpy().reshape(-1,1))\n",
    "\n",
    "# as in the line above, it's simple to add new columns to our existing DataFrame\n",
    "df[\"raw_error\"] = df.preds - df.mass\n",
    "\n",
    "df.plot.scatter(x=\"mass\", y=\"preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's add a line of best fit here, what we expect to see if predictions == actual mass.\n",
    "\n",
    "As you can see, it's a `bag o'shite` but the thing to note is that the *error* in these predictions is the difference between each blue point and the green line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "p1 = sns.scatterplot(data=df, x='mass', y='preds', ax=ax)\n",
    "p2 = sns.lineplot(data=df, x='mass', y='mass', color='g', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# What's gone wrong?\n",
    "We will do another pandas filter here, but this time on column name. Then we will sort on the error column to find the worst offenders.\n",
    "\n",
    "It's fair to say it's all Jabba's fault!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"name\", \"height\", \"mass\", \"raw_error\"]\n",
    "\n",
    "df[cols].sort_values(\"raw_error\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Can we put a number on the error?\n",
    "There's lots of ways, and what you use depends on the type of thing you are predicting (a category or a continuous variable). We are doing the latter so the favourites are:\n",
    "\n",
    "* Mean Squared Error: Take the errors from above, square them and add them together. This means that big errors get magnified, helping us to see when something is *really* wrong\n",
    "* Root Mean Squared Error: Take the square root of the Mean Squared Error. Useful as the result is easier to relate to your data.\n",
    "* Mean Absolute error: Average of the raw errors, a bit crap as negatives cancel out the positives!\n",
    "\n",
    "Have a look at the below and try to relate what you are seeing with the bullets and the table above, do you get why the answers are different? Which do you think is best in this instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# sklearn also provides us with numerous methods to calculate the performance of our models\n",
    "\n",
    "{\n",
    " \"mean_squared_error\": mean_squared_error(df.mass, df.preds),\n",
    " \"root_mean_squared_error\": mean_squared_error(df.mass, df.preds, squared=False),\n",
    " \"mean_absolute_error\": mean_absolute_error(df.mass, df.preds)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# What do we do about Jabba?\n",
    "Oh, lots of things. We could add species as a variable in the model, allowing it to learn that Hutts are a little different to everyone else. We could just drop him from the data and tell the customer \"We can't predict Hutts\". Given the data we have I'm going with the second option.\n",
    "\n",
    "I'm also going to add some complexity here. It's generally considered bad form to evaluate your model with the same data that you trained it with. It could just learn some nuance in your data and not work in production!\n",
    "\n",
    "As such, we are going to split the data into a train and a test set while we are at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Filter out all Hutts, they just don't lend themselves to BMI calculations!\n",
    "df_no_hutts = df.loc[df.species != \"Hutt\"]\n",
    "\n",
    "# shape gives us row, column count so we can be sure we've not done anything silly\n",
    "print(df.shape, df_no_hutts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now split the data into training and test sets. Check shape again.\n",
    "height_train, height_test, mass_train, mass_test = train_test_split(df_no_hutts.height, df_no_hutts.mass, test_size=0.20)\n",
    "\n",
    "print(height_train.shape, height_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the new model\n",
    "mod_2 = LinearRegression()\n",
    "mod_2.fit(height_train.to_numpy().reshape(-1,1), mass_train)\n",
    "\n",
    "preds = mod_2.predict(height_test.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The next bit is up to you!\n",
    "I've given you some empty cells below but you can make more or delete them as required. Go steal some code from higher up (or just t'internet) and tell me:\n",
    "\n",
    "* Which model is better?\n",
    "* Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}